# ðŸŽµ Automated-Music-Data-ETL-Analytics-Pipeline---using-python


> **Project in Brief**
>
> The goal is to build an **ETL pipeline** that automatically collects and processes trending music data (e.g., global top songs from Spotify) every week. Over time, this will create a dataset that can help your client (a music label) **analyze patterns in popular music** (e.g., genres, artists, song structures) and potentially guide their own production.

---

## ðŸ”¹ Architecture Overview

`Spotify API â†’ Lambda Extract â†’ Raw S3 â†’ Lambda Transform â†’ Processed S3 â†’ Glue â†’ Athena`

![Architecture diagram](assets/architecture.png)

> Brief: A Lambda-based, serverless pipeline that extracts playlist data from Spotify, stores raw JSON in S3, triggers a second Lambda to transform and persist cleaned Parquet/CSV artifacts, catalogs them with Glue, and enables SQL analytics through Athena.

---

## ðŸ”¹ ETL Pipeline Components

### 1. Extract

* **Source:** Spotify API (use Spotipy or any preferred Python client).
* **Implementation:** Python script running inside **AWS Lambda**.
* **Scheduling:** CloudWatch Events (EventBridge) scheduled rule â€” weekly trigger.
* **Output:** Raw JSON files written to `s3://<bucket>/raw/spotify/<YYYY-MM-DD>/playlist.json`.

**Important environment variables** for the extractor Lambda:

```
SPOTIPY_CLIENT_ID=<your_client_id>
SPOTIPY_CLIENT_SECRET=<your_client_secret>
SPOTIPY_REDIRECT_URI=https://example.com/callback
S3_BUCKET=<your_bucket>
PLAYLIST_ID=<spotify_playlist_id_or_env_override>
```

### 2. Transform

* **Trigger:** S3 `ObjectCreated` event on the `raw/spotify/` prefix.
* **Job:** Lambda function reads JSON, cleans and normalizes data into tables (songs, artists, albums, track_features, playlist_metadata).
* **Output formats:** Parquet (preferred for analytics) and/or CSV, written to `s3://<bucket>/processed/spotify/<table>/year=YYYY/month=MM/day=DD/`.

Example transform tasks:

* Flatten nested JSON for artists and album details.
* Normalize numeric columns (popularity, duration_ms).
* Enrich tracks with audio features (via Spotify audio-features endpoint) and compute derived columns (e.g., duration_min).

### 3. Load (Catalog + Query)

* **Glue Crawler** scans the `processed/spotify/` prefix and infers table schemas.
* **Glue Data Catalog** stores table metadata.
* **Amazon Athena** is used to run SQL queries and build analytics dashboards over S3 data.

Example Athena query â€” Top 10 artists by average popularity in the last 6 months:

```sql
WITH recent_tracks AS (
  SELECT *, date_parse(date, '%Y-%m-%d') AS track_date
  FROM spotify_tracks
  WHERE track_date >= date_add('month', -6, current_date)
)
SELECT artist_name, avg(popularity) AS avg_pop
FROM recent_tracks
GROUP BY artist_name
ORDER BY avg_pop DESC
LIMIT 10;
```

---

## ðŸ”¹ Folder structure (suggested)

```
â”œâ”€â”€ README.md
â”œâ”€â”€ extractor/
â”‚   â”œâ”€â”€ lambda_function.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ transformer/
â”‚   â”œâ”€â”€ lambda_function.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ sam-template.yaml   # or cloudformation / terraform modules
â”‚   â””â”€â”€ deploy.sh
â”œâ”€â”€ analytics/
â”‚   â”œâ”€â”€ athena-queries.sql
â”‚   â””â”€â”€ notebooks/
â””â”€â”€ assets/
    â”œâ”€â”€ architecture.png
    â””â”€â”€ sample_output.png
```

---

## ðŸ”¹ Example Lambda Extractor (handler sketch)

```python
# extractor/lambda_function.py
import os
import json
import boto3
from spotipy import Spotify
from spotipy.oauth2 import SpotifyClientCredentials

s3 = boto3.client('s3')

def lambda_handler(event, context):
    client_id = os.environ['SPOTIPY_CLIENT_ID']
    client_secret = os.environ['SPOTIPY_CLIENT_SECRET']
    playlist_id = os.environ.get('PLAYLIST_ID')
    bucket = os.environ['S3_BUCKET']

    auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)
    sp = Spotify(auth_manager=auth_manager)

    playlist = sp.playlist(playlist_id)
    key = f"raw/spotify/{context.aws_request_id}/playlist.json"
    s3.put_object(Bucket=bucket, Key=key, Body=json.dumps(playlist))

    return {"statusCode": 200, "body": key}
```

---

## ðŸ”¹ Suggested IAM Permissions (minimum)

* **Extractor Lambda**:

  * `s3:PutObject` on the raw prefix
  * `logs:CreateLogGroup`, `logs:CreateLogStream`, `logs:PutLogEvents`
* **Transformer Lambda**:

  * `s3:GetObject` on raw prefix
  * `s3:PutObject` on processed prefix
  * `glue:CreateTable`, `glue:UpdateTable` (if managing catalog programmatically)
* **Glue Crawler**: permissions to read processed prefix and write to Glue Data Catalog
* **Athena**: permissions to read from S3 processed prefix and to run queries

---

## ðŸ”¹ Deployment / Infra options

* Use **AWS SAM** or **Serverless Framework** to package and deploy Lambdas, deploy CloudWatch rules and S3 notifications.
* Alternatively, use **Terraform** or native CloudFormation templates.

Example SAM snippet for scheduled extractor (infra/sam-template.yaml):

```yaml
Resources:
  SpotifyExtractor:
    Type: AWS::Serverless::Function
    Properties:
      Handler: lambda_function.lambda_handler
      Runtime: python3.11
      Environment:
        Variables:
          S3_BUCKET: !Ref DataBucket
          SPOTIPY_CLIENT_ID: 'REPLACE_ME'
          SPOTIPY_CLIENT_SECRET: 'REPLACE_ME'
      Events:
        WeeklyTrigger:
          Type: Schedule
          Properties:
            Schedule: rate(7 days)
```

---

## ðŸ”¹ Observability & Cost

* Enable CloudWatch logs and set retention (e.g., 30 days).
* Use CloudWatch metrics and alarms on Lambda errors and duration.
* Parquet + partitioning reduces Athena query costs and improves performance.

---

## ðŸ”¹ Sample Athena queries / analytics ideas

* Trend genres over time (`GROUP BY genre, month`)
* Average energy / danceability for top tracks vs non-top tracks
* Artist churn rate â€” new vs returning artists in the weekly top playlist

---

## ðŸ”¹ Images & Assets

Place your images in `assets/` and reference them in the README. Example filenames used above:

* `assets/architecture.png` â€” architecture diagram (recommended size: 1200Ã—600)
* `assets/sample_output.png` â€” sample query screenshot (recommended size: 1000Ã—600)

---

## ðŸ”¹ Contributing

Contributions welcome â€” open issues and PRs. Please include tests for transformer logic and keep Lambda package sizes small (use Lambda layers if needed).

---

## ðŸ”¹ License

MIT Â© Your Name

---

## ðŸ”¹ Contact

Project maintainer â€” `your.email@example.com`

*Generated README for the Weekly Spotify Trending ETL Pipeline. Replace placeholders and secrets before deploying.*
